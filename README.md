# Train NLP models on TensorFlow # 

All the models are tested on TensorFlow 1.15.

## LSTM ##

LSTM (Long Short-Term Memory) is an artificial recurrent neural network architecture. The key idea is to use LSTM units partially solve the vanishing gradient problem, since LSTM units allow gradients to also flow unchanged. The similar idea has been applied to convolutional neural network, i.e., residual nerual network. 

The implementation of LSTM is tested on Universal Dependencies Dataset for POS Tagging task.

## BiLSTM ##


## BERT ##

